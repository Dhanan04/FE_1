{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737a925d",
   "metadata": {},
   "source": [
    "#Ans1.) \n",
    "\n",
    "Missing values in a dataset refer to the absence of values in one or more variables. It is essential to handle missing values because they can introduce bias, reduce the statistical power of the analysis, and lead to incorrect conclusions. Some algorithms that are not affected by missing values include:\n",
    "\n",
    "Tree-based algorithms such as Decision Trees and Random Forests\n",
    "Naive Bayes\n",
    "K-nearest neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dffc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6af84689",
   "metadata": {},
   "source": [
    "#Ans2.) \n",
    "\n",
    "Techniques used to handle missing data include:\n",
    "\n",
    "Mean, median, or mode imputation\n",
    "\n",
    "Forward fill or backward fill\n",
    "\n",
    "Removing rows or columns with missing values\n",
    "\n",
    "Using machine learning algorithms to predict missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02738c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imputation:\n",
      "       A     B\n",
      "0  1.00   6.0\n",
      "1  3.25   7.0\n",
      "2  3.00   8.0\n",
      "3  4.00   9.0\n",
      "4  5.00  10.0\n",
      "\n",
      "Forward fill:\n",
      "      A     B\n",
      "0  1.0   6.0\n",
      "1  1.0   7.0\n",
      "2  3.0   7.0\n",
      "3  4.0   9.0\n",
      "4  5.0  10.0\n",
      "\n",
      "Drop rows with missing values:\n",
      "      A     B\n",
      "0  1.0   6.0\n",
      "3  4.0   9.0\n",
      "4  5.0  10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame with missing values\n",
    "data = {'A': [1, np.nan, 3, 4, 5],\n",
    "        'B': [6, 7, np.nan, 9, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mean imputation\n",
    "df_mean = df.fillna(df.mean())\n",
    "print(\"Mean imputation:\\n\", df_mean)\n",
    "\n",
    "# Forward fill\n",
    "df_ffill = df.ffill()\n",
    "print(\"\\nForward fill:\\n\", df_ffill)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_dropna = df.dropna()\n",
    "print(\"\\nDrop rows with missing values:\\n\", df_dropna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00cc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f78513f",
   "metadata": {},
   "source": [
    "#Ans3.) \n",
    "\n",
    "Imbalanced data refers to a situation where the classes in the dataset are not represented equally. If imbalanced data is not handled, it can lead to biased models that favor the majority class and perform poorly on the minority class. This can result in misleading evaluation metrics and incorrect predictions for the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3038c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8748086d",
   "metadata": {},
   "source": [
    "#Ans4.) \n",
    "\n",
    "Up-sampling involves increasing the number of instances in the minority class to balance the dataset.\n",
    "\n",
    "Down-sampling involves reducing the number of instances in the majority class to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f62167",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming df is your DataFrame containing the dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Replace 'target' with the actual name of your target column\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Separate majority and minority classes\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_majority \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajority\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m df_minority \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminority\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Upsample minority class\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming df is your DataFrame containing the dataset\n",
    "# Replace 'target' with the actual name of your target column\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['target'] == 'majority']\n",
    "df_minority = df[df['target'] == 'minority']\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority))\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14fb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76b6b82b",
   "metadata": {},
   "source": [
    "#Ans5.) \n",
    "\n",
    "Data augmentation is a technique used to artificially increase the size of a dataset by applying transformations to the existing data. SMOTE (Synthetic Minority Over-sampling Technique) is a type of data augmentation specifically designed for imbalanced datasets. It generates synthetic samples for the minority class by interpolating between existing minority class instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0edb5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\dell\\anaconda3\\lib\\site-packages\\diamondpriceprediction-0.0.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n",
      "DEPRECATION: Loading egg at c:\\users\\dell\\anaconda3\\lib\\site-packages\\fonttools-4.42.1-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\dell\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install imbalanced-learn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      4\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE()\n\u001b[0;32m      5\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\dell\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d4d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed6e12f0",
   "metadata": {},
   "source": [
    "#Ans6.) \n",
    "\n",
    "Outliers in a dataset are data points that significantly differ from the rest of the observations. It is essential to handle outliers because they can skew statistical analyses, affect the performance of machine learning algorithms, and lead to incorrect conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96a602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c13f02d6",
   "metadata": {},
   "source": [
    "#Ans7.) \n",
    "\n",
    "Techniques to handle missing data in analysis include:\n",
    "\n",
    "Mean, median, or mode imputation\n",
    "\n",
    "Forward fill or backward fill\n",
    "\n",
    "Removing rows or columns with missing values\n",
    "\n",
    "Using machine learning algorithms to predict missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c86a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2651204b",
   "metadata": {},
   "source": [
    "#ans8.)\n",
    "\n",
    "Strategies to determine if missing data is missing at random or if there is a pattern include:\n",
    "\n",
    "Visualizing missing data patterns using heatmaps or bar plots\n",
    "Testing for correlation between missing values and other variables\n",
    "Using statistical tests such as Little's MCAR test to assess randomness of missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69f8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ca373f",
   "metadata": {},
   "source": [
    "#Ans9.) \n",
    "\n",
    "When dealing with an imbalanced dataset in a medical diagnosis project, where the majority of patients do not have the condition of interest, and only a small percentage do, some strategies to evaluate the performance of the machine learning model include:\n",
    "\n",
    "Use appropriate evaluation metrics: Instead of accuracy, which can be misleading in imbalanced datasets, use metrics like precision, recall, F1-score, and area under the receiver operating characteristic curve (AUC-ROC).\n",
    "\n",
    "Resampling techniques: Employ techniques like oversampling the minority class, undersampling the majority class, or generating synthetic samples using methods like SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset before training the model.\n",
    "\n",
    "Cost-sensitive learning: Adjust the misclassification costs for different classes to reflect the imbalance in the dataset. For instance, penalize misclassification of the minority class more heavily than the majority class during model training.\n",
    "\n",
    "Ensemble methods: Utilize ensemble methods like Random Forests, Gradient Boosting Machines (GBM), or AdaBoost, which are inherently robust to imbalanced datasets and can effectively handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae29d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b403ef",
   "metadata": {},
   "source": [
    "#Ans10.) \n",
    "\n",
    "When facing an unbalanced dataset where the majority of customers report being satisfied while attempting to estimate customer satisfaction for a project, some methods to balance the dataset and down-sample the majority class include:\n",
    "\n",
    "Random under-sampling: Randomly remove instances from the majority class to match the size of the minority class, ensuring a balanced dataset.\n",
    "\n",
    "Cluster-based under-sampling: Use clustering algorithms to identify clusters within the majority class and then randomly sample instances from each cluster to down-sample the majority class.\n",
    "\n",
    "Tomek links: Identify pairs of instances from different classes that are nearest neighbors (Tomek links) and remove instances from the majority class, which form Tomek links with instances from the minority class.\n",
    "\n",
    "Edited nearest neighbors: Use the edited nearest neighbors algorithm to remove instances from the majority class that are misclassified by their nearest neighbors from the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78827c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f06f87e2",
   "metadata": {},
   "source": [
    "#Ans11.) \n",
    "\n",
    "When dealing with a dataset that has a low percentage of occurrences of a rare event, and you need to estimate the occurrence of this rare event, some methods to balance the dataset and up-sample the minority class include:\n",
    "\n",
    "Random over-sampling: Randomly duplicate instances from the minority class to increase its size and balance the dataset.\n",
    "\n",
    "Synthetic Minority Over-sampling Technique (SMOTE): Generate synthetic samples for the minority class by interpolating between existing minority class instances, thereby increasing its size and balancing the dataset.\n",
    "\n",
    "Adaptive Synthetic Sampling (ADASYN): Similar to SMOTE, ADASYN generates synthetic samples for the minority class, but it places more emphasis on regions of the feature space where the class distribution is sparse, making it particularly suitable for highly imbalanced datasets.\n",
    "\n",
    "SMOTE-ENN (SMOTE + Edited Nearest Neighbors): Apply SMOTE to over-sample the minority class and then use edited nearest neighbors to remove noisy and borderline instances from both classes, resulting in a more robust up-sampling approach.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341aef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f409c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
